# Model 03: Multi-Layer Perceptron (MLP) – Empirical Analysis Plan

This document details the practical implementation and performance analysis of the model. For the full historical context and theoretical background, please refer to our **[Theoretical Deep Dive](./01_deep_dive.md)**.

## 2.1. Proposed "Success Case" Experiment

To showcase the strengths of the Multi-Layer Perceptron, we propose a classic experiment on a problem that a single-layer network (perceptron) cannot solve, but a multi-layer network can. This will highlight the power of having multiple layers.

* **Dataset/Problem:** We will use the **XOR classification problem** as a quintessential success case. XOR is the simplest two-input binary classification task that is **not linearly separable**. Specifically, we have inputs (x1, x2) with outputs defined as XOR (true only if one of x1 or x2 is true, and false if both are the same). We may also demonstrate on a slightly less trivial dataset like the “two moons” dataset (two interleaving half-circles in 2D) which is another classic non-linear pattern. Both XOR and two-moons are straightforward to generate (e.g., using NumPy or scikit-learn), and they require a network with at least one hidden layer to learn correctly. Using such synthetic data ensures we clearly know what the network should achieve (and we can visualize it easily).

* **Why this dataset is appropriate:** XOR is historically important – it was the very problem that perceptrons failed at, leading to the need for multi-layer networks. A single-layer perceptron will forever be stuck at 75% accuracy on XOR at best (essentially it can only get 3 out of 4 examples right, since it tries to cut with one line). In contrast, a 2-layer MLP (with a small hidden layer of 2 neurons) can learn to produce the correct XOR truth table perfectly. This makes XOR a perfect minimal example to **prove the capability of multiple layers**. The two-moons dataset similarly cannot be solved by any linear boundary, but a modest MLP can learn the curved decision boundary. By picking such problems, we isolate the benefit of the MLP’s non-linearity without requiring a large network or heavy computation – it’s very clear when the MLP succeeds and why.

* **Experimental Setup:** We will construct a small MLP, for example with 2 input neurons, 2 hidden neurons, and 1 output neuron (for XOR). We’ll train it using a suitable algorithm (stochastic gradient descent or a library’s optimizer) on the four XOR data points. We’ll monitor the training process for convergence. For two-moons, we might use a slightly larger network (e.g., 2 inputs -> 4 hidden -> 1 output) and train on a sample of points labeled in two interleaved moon shapes. Key hyperparameters like learning rate and number of epochs will be chosen so that the network converges (this shouldn’t be hard as these are simple tasks).

* **Expected Outcome:** The MLP should **achieve near-perfect accuracy** on these tasks. In the XOR case, we expect the network to correctly output 0 or 1 for all four input combinations after training – in other words, 100% training accuracy. For two-moons, we expect the decision boundary learned by the MLP to successfully separate the two half-circle clusters with very few mistakes (we can measure accuracy on a test split or the entire set, expecting it to be very high, e.g., > 95% if properly trained). The key success criterion is that the MLP finds a **non-linear decision boundary** that a perceptron could not. For XOR, that boundary in the 2D input space might look like two separate lines dividing the space into the XOR pattern (it’s effectively an X-shaped decision region). For two-moons, the boundary will be a curved line wrapping around the moons.

* **Metrics and Visualizations:** To conclusively prove success, we will employ a few approaches:

  * **Accuracy and Loss:** We’ll report the final accuracy of the model on the problem (and perhaps a small test set for two-moons). Also, we’ll plot the training loss curve (error vs. training iterations) to show that the network indeed converges, whereas a single-layer perceptron’s loss would plateau above the minimum. A successful MLP experiment will show the loss dropping to near zero over training epochs, indicating the network has essentially perfectly fit the data (for XOR this happens quickly given how small it is).
  * **Decision Boundary Plot:** Especially for these 2D input problems, a compelling visualization is to plot the learned decision boundary of the MLP. We plan to create a 2D plot showing input space (x1 vs x2), scatter the data points with different symbols/colors for the classes, and overlay the decision regions as predicted by the MLP. For XOR, this will reveal that the network has created a **piecewise linear boundary** (two linear segments crossing) that successfully separates the “true” outputs (1s) from “false” outputs (0s) in the corners of the space. For two-moons, the plot will show a smooth curved boundary between the two moon shapes. This visualization directly demonstrates the MLP’s non-linear separating power, in contrast to a single linear separator which would be just one line unable to do the job.
  * **Intermediate Activations (if insightful):** We could also inspect the hidden layer outputs for various inputs to illustrate how the network is solving the problem. For XOR, for instance, we might show that hidden neuron 1 learned to detect “x1 OR x2” (outputs high except when both inputs are 0) and hidden neuron 2 learned something like “x1 AND x2” (outputs high only when both inputs are 1). This kind of visualization (maybe a truth table of hidden neuron activations) can provide an intuitive understanding that the MLP internally discovered the logical features needed. Although not strictly necessary to prove success, it’s an enlightening peek under the hood, reinforcing how the multi-layer structure finds a correct representation.

By conducting this success-case experiment, we will concretely demonstrate the fundamental point that **MLPs can solve problems that are unsolvable by single-layer networks**. When we see the network correctly modeling XOR or separating the two moons, it validates the claims from the theory: multiple layers + non-linear activation give the network the capacity to represent complex decision surfaces. This experiment essentially replays the breakthrough moment from the 1960s/1980s in a modern way – showing that yes, with the right learning algorithm, the MLP nails XOR (and more), where the perceptron fails.

## 2.2. Proposed "Failure Case" Experiment

Having seen where the MLP shines, it’s equally important to examine its **limitations**. We propose an experiment on a problem known to be challenging for plain multi-layer perceptrons, to expose the primary weaknesses of this model. This will motivate why subsequent architectures (like convolutional neural networks, e.g. LeNet-5) were developed.

* **Dataset/Problem:** We will tackle an **image classification task** that reveals the shortcomings of a fully-connected MLP. A suitable choice is the **MNIST handwritten digit dataset** (images of 28×28 pixel digits 0-9) or a similar image dataset, but with a twist: we’ll observe how an MLP handles variations in the input such as shifted or distorted images. Alternatively (or additionally), we could try a more complex image dataset like **CIFAR-10** (32×32 color images of various objects) to really push the limits. For clarity, let’s outline the MNIST case:

  * We train a vanilla MLP on the MNIST training set (which contains centered digit images). The network architecture might be something like 784 inputs (28×28 pixels) → 100 hidden neurons → 10 outputs (one per digit class). This network will be trained with backpropagation to classify digits.
  * Then, to simulate a scenario that highlights MLP limitations, we evaluate this trained MLP on a modified test set where the digit images are **shifted** a bit off-center or have some slight **affine distortions**. (For example, take each test image and translate it 2-3 pixels in a random direction, or introduce a small rotation).
    The reason for this modification is that a plain MLP has no built-in mechanism to handle such translations or distortions – each pixel is treated as a separate feature, so if the digit moves, the activation pattern the MLP learned in training will no longer align with the new pixel positions, causing errors.

* **Why this exposes a challenge:** MLPs lack **spatial invariance** and **local receptive fields**. Unlike a human (or a convolutional neural network), which recognizes a “3” whether it’s centered or slightly left, a standard MLP trained on centered “3”s will not recognize a “3” that’s shifted, because that specific pattern of pixels was not seen during training. The MLP has essentially memorized weights for exact pixel positions. This makes it data-inefficient and not robust to shifts/rotations. Moreover, the number of weights in an MLP dealing with images is huge (784 inputs \* 100 hidden = 78,400 weights just in the first layer for the above architecture), meaning it has a lot of parameters to fit and tends to overfit unless we have very large datasets. By using image data, we are deliberately hitting a known weakness: **MLPs do not exploit the 2D structure of images**. They also don’t share weights across different positions, so they need to learn separately for every pixel pattern. This is in contrast to convolutional networks (like LeNet-5) which were specifically designed to address these issues.

* **Experimental Setup:** We will train the MLP on the normal training set (e.g., MNIST). We expect it to do reasonably well on standard test images (maybe achieving around 90-95% accuracy if well-tuned, which is decent but not state-of-the-art). Then we’ll test the same model on altered inputs (shifted digits) or on a more complex dataset. Possibly two parts:

  1. **Generalization test on shifted MNIST:** Create a variant of the MNIST test set with each image randomly shifted within a few pixels. Evaluate the trained MLP on this set without any additional training.
  2. **Training on CIFAR-10 or a similar more complex set:** Attempt to train a simple MLP on CIFAR-10 to classify 10 object categories. This will push the model to its capacity limits because CIFAR-10 images (32×32 color, so 3072 input features) and complex object variability are far harder than MNIST. We might observe training difficulties or poor performance here directly.

  We will monitor training and validation accuracy as usual. Particularly, we will look for signs of **overfitting** or the inability to reach high accuracy due to the network’s limitations.

* **Expected Outcome:** For the **shifted MNIST scenario**, we expect a significant drop in accuracy when the MLP is tested on images that are simply shifted or slightly different from what it saw. For example, if the MLP got 94% on normal MNIST test, it might only get something like 60% on shifted images (this is illustrative; actual numbers to be determined by experiment, but the drop should be noticeable). The mistakes will likely be because the network misclassifies digits that moved – what it learned for “where the loops and lines of a digit are” doesn’t apply when those loops move to a new location in the input grid. Essentially, the network fails to generalize *positionally*. A human or a convolutional model would not be fooled by such a small shift, but the MLP is, due to lack of built-in invariance.

  In the **CIFAR-10 training** case, we expect the MLP might struggle even on the training data unless we use a very large model, and even then it will probably memorize some patterns without truly capturing the concept of an “airplane” or “dog” robustly. Likely outcomes: the training accuracy might increase slowly and possibly reach a high number (if the model has enough capacity it can overfit), but the validation accuracy will remain low (perhaps only 40-50%, or basically not much better than random guessing for 10 classes which is 10%). Another possibility is that the MLP with limited hidden neurons simply cannot represent the complexity of CIFAR and plateaus at a low accuracy even on training. In either case, it’s a failure relative to state-of-the-art on this problem. The core reasons: (a) too many input features and not enough structural assumptions, so the network has millions of weights and not enough data to tune them all effectively, and (b) no handling of the fact that say an object could appear anywhere in the image – the MLP would have to learn separate detectors for every possible position of a feature, which is inefficient.

  We anticipate seeing specific failure modes, such as:

  * **Overfitting**: The training loss may go very low while the validation loss diverges or stays high. This indicates the MLP memorized the training images but can’t generalize. This is likely for CIFAR-10 if a large MLP is used.
  * **High error on slight variations**: For shifted MNIST, even though those images are essentially the “same” digits just moved, the error will spike, indicating brittleness.
  * **Confusion between classes**: We might look at a confusion matrix (for example, on MNIST shifts, the MLP might confuse a shifted “6” with “8” or “0” because it didn’t learn a proper concept of 6’s shape, just pixel positions).
  * **Weight inspection**: If we visualize the first-layer weights of the MLP (which can be reshaped to image patches), on a well-trained network for images they sometimes look like stroke detectors or part templates. However, an MLP might learn some local features, but if it overfit, those weight visualizations might look noisy or not interpretable (especially if it memorized weird pixel correlations). For CIFAR, first-layer weights of an MLP are often hard to interpret as anything meaningful, whereas for a CNN they’d be edges or color blobs. This difference could be a clue that the MLP isn’t extracting robust features.

* **Metrics and Diagnoses:** To best diagnose the reason for failure, we will collect and present:

  * **Accuracy on standard vs. perturbed data:** For the MNIST case, compare the model’s accuracy on the normal test set vs the shifted test set. The delta quantifies how sensitive the model is to small input changes.
  * **Training vs Validation Curves:** Especially for the CIFAR experiment, plot the training accuracy and validation accuracy over epochs. We expect to see a gap (training goes much higher than validation) if overfitting occurs, or both remain flat and low if underfitting/capacity issues occur. Either scenario is informative: a big gap = model memorized data but lacks generalization (due to not capturing invariant features), flat low = model couldn’t even find adequate representation (could be capacity or optimization issue).
  * **Confusion Matrix:** On the difficult dataset, see which classes are being predicted incorrectly frequently. This might show, for example, the MLP tends to predict one or two classes for almost everything (a common failure mode when it can’t really differentiate – it might default to guessing the majority class or something it has slightly better cues for).
  * **Example errors:** Present a few example images that the MLP gets wrong and explain why that might be. For instance, show a digit “5” that when shifted looks like where a “2” used to be in training, so the MLP misclassifies it as 2. Or in CIFAR, maybe show that the MLP misclassifies a cat as a dog unless the cat is in a very specific pose it saw, etc. Visualizing these errors makes it tangible what kind of patterns the MLP is failing to handle.

Through this failure-case experiment, we aim to underscore the main limitations of plain MLPs:

1. **Sensitivity to input location/orientation** – they don’t inherently know that a pattern can move in the input space (no translational invariance).
2. **Parameter inefficiency** – they use a lot of weights for image tasks, making them data-hungry and prone to overfitting.
3. **No exploitation of local structure** – every input dimension is treated independently, so relationships that are local (like adjacent pixels forming an edge) are not explicitly captured unless learned from scratch.
4. **Scalability issues** – as tasks get more complex (bigger images, more variation), a fully-connected net needs exponentially more neurons and training data to cope, which becomes infeasible.

We expect the outcome of this experiment to clearly illustrate these issues. For example, if the MLP fails to generalize to shifted images, it directly suggests that the model needs a mechanism to handle shifts – setting the stage for discussing convolution/pooling. If the model severely overfits or lags on CIFAR, it suggests we need a better architectural bias (like local receptive fields and weight sharing) to make learning feasible.

## 2.3. The Transition Narrative

The weakness exposed in the failure case is *exactly* the problem that **LeNet-5** was designed to solve. It addresses this by introducing **convolutional layers and sub-sampling (pooling)**, which give the network built-in translation invariance and drastically reduce the number of parameters. In LeNet-5’s architecture, neurons are only connected to small local patches of the input (like small image regions) and the same set of weights (filters) is used across different positions. This means a feature learned for one part of the image will work on any other part – the network no longer needs to relearn the concept of “vertical stroke” for every pixel location, for example. The pooling layers in LeNet-5 further help by down-sampling the feature maps, making the representations **more tolerant to shifts and distortions** (a slight shift in input leads to almost the same pooled representation). In summary, LeNet-5 directly tackles the MLP’s shortcomings on images: it **constrains the connections** in a smart way (local receptive fields, weight sharing) to fight overfitting and **incorporates spatial hierarchy**, enabling it to handle image variability much more effectively. Thus, the failures we observed with a plain MLP on image data – many parameters, sensitivity to position – are overcome by LeNet-5’s convolutional design, heralding a new era of neural network models better suited for complex real-world data like images. The transition from MLP to LeNet-5 is a prime example of how adding structural knowledge into the network’s design leads to a leap in performance and robustness for visual tasks.
