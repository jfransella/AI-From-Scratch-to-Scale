# AI From Scratch to Scale: A Hands-On Journey Through the History of Neural Networks

[cite_start]This repository chronicles a learning journey through the history of neural networks, from the foundational Perceptron to modern, large-scale architectures[cite: 91]. [cite_start]The primary goal is twofold: first, to gain a deep, practical, and historical understanding of these models; and second, to create a high-quality, open-source educational resource that allows others to follow the same path[cite: 89, 90].

## Learning Methodology

[cite_start]Each **Keystone** model in this project is tackled with a consistent four-phase learning cycle[cite: 111, 185]. [cite_start]This methodology ensures a deep understanding by building a narrative around each model's invention and purpose[cite: 182].

* [cite_start]**Understand**: We first perform a theoretical deep dive into the model's historical context, the problem it was designed to solve, and its core mathematical and architectural innovations[cite: 112, 188].
* [cite_start]**Build**: We then implement the model in code, starting from scratch with libraries like NumPy and later using modern frameworks like PyTorch[cite: 113, 118, 119].
* [cite_start]**Demonstrate Strength**: We train the model on a dataset where it is known to excel, analyzing its success[cite: 114, 228].
* [cite_start]**Expose Weakness**: We then use a different problem to clearly demonstrate the model's limitations, creating the motivation for the next model in our journey[cite: 115, 230].

## Project Roadmap

This repository is structured into modules that follow the historical evolution of neural networks. [cite_start]The engagement level for each model is defined as **Keystone** (full implementation and analysis), **Conceptual** (theory and architecture review), or **Side-quest** (exploration of a parallel paradigm)[cite: 123, 124, 126, 129].

### [cite_start]Module 1: The Foundations (From Scratch) [cite: 134]
[cite_start]*The goal is to understand the basic mechanics of a neuron and a learning algorithm.* [cite: 135]
| # | Model | Engagement | Status |
|---|---|---|---|
| 1 | [The Perceptron](01_perceptron/) | [cite_start]`Keystone` [cite: 136] | âœ… Complete |
| 2 | ADALINE | [cite_start]`Conceptual` [cite: 137] | Not Started |
| 3 | Multi-Layer Perceptron (MLP) | [cite_start]`Keystone` [cite: 138] | Not Started |
| 4 | Hopfield Network | [cite_start]`Side-quest` [cite: 139] | Not Started |

### [cite_start]Module 2: The CNN Revolution (Intro to Frameworks) [cite: 140]
[cite_start]*The goal is to understand how networks process spatial data like images.* [cite: 141]
| # | Model | Engagement | Status |
|---|---|---|---|
| 5 | LeNet-5 | [cite_start]`Keystone` [cite: 142] | Not Started |
| 6 | AlexNet | [cite_start]`Keystone` [cite: 143] | Not Started |
| 7 | VGGNet | [cite_start]`Conceptual` [cite: 144] | Not Started |
| 8 | GoogLeNet | [cite_start]`Conceptual` [cite: 145] | Not Started |
| 9 | ResNet | [cite_start]`Keystone` [cite: 146] | Not Started |

*(Additional modules for CNN Applications, Sequence Models, the Generative Era, and the Modern Paradigm will be added here as the project progresses.)*

## Our Philosophy & Tools

* [cite_start]**Code as a Learning Tool**: Our code is written to be exceptionally clear and well-documented, prioritizing readability to serve as an educational artifact[cite: 255, 257, 258].
* [cite_start]**Historical Fidelity**: We aim to stay as close as possible to the original specifications of each model to understand the historical context[cite: 109].
* [cite_start]**Technology**: We use **Python** and **VS Code** for development[cite: 98]. [cite_start]Early models are built with **NumPy** [cite: 99][cite_start], while later models leverage **PyTorch** or **TensorFlow**[cite: 105].

## License

This project is intended as a public learning resource. [cite_start]All code and documentation are licensed under the **MIT License**[cite: 103, 321].# AI-From-Scratch-to-Scale