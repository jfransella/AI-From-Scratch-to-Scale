### **Part 2: Empirical Analysis Plan (`docs/02_empirical_analysis.md`)**

#### 2.1. Backward Link

This document details the practical implementation and performance analysis of the model. For the full historical context and theoretical background, please refer to our **[Theoretical Deep Dive](./01_deep_dive.md)**.

#### 2.2. Proposed "Success Case" Experiment

To demonstrate the perceptron’s strengths, we will start with a **classic linearly separable dataset**, where we know the perceptron should excel. A suitable choice is to **generate a simple 2D linearly separable dataset** using NumPy – for example, points in a plane that can be separated by a straight line. Concretely, we might create two clusters of points: one cluster centered around $(0, 0)$ for class 0, and another cluster centered around $(1, 1)$ for class 1. We will ensure these clusters don’t overlap and can be cleanly separated by a line (say, $x_1 + x_2 = 0.5$ could divide them). This artificial dataset is straightforward but very illustrative: it mirrors the kind of task the perceptron was born to solve (recall that the perceptron is guaranteed to converge on any linearly separable data).

**Why this dataset?** Linearly separable data is the perceptron’s “happy place.” By design, a perceptron is a linear classifier, so if a perfect linear boundary exists, the perceptron should find it given enough training. Using a simple 2D dataset allows us to **visualize the decision boundary** easily and see the perceptron’s success. We could alternatively use a known dataset like the Iris dataset (but only the two classes that are linearly separable, e.g. Setosa vs Versicolor) or a classic binary classification on something like adult income where a linear model does well. However, the simplicity of a synthetic 2D example is hard to beat for clarity.

**Expected outcome**: The perceptron should rapidly reach high accuracy on this task – in fact, 100% training accuracy is expected if the data is truly linearly separable. We anticipate that after training, the perceptron will have learned weights corresponding to the equation of the separating line. For instance, it might discover something like $2x_1 + 2x_2 - 1 > 0$ as the condition for class 1 (one possible separating line between the clusters mentioned above).

**Metrics and visualizations**: To prove success, we will employ several approaches:

* **Accuracy and Loss Curves**: We will track the perceptron’s classification accuracy on the training set over epochs. We expect to see the accuracy climb to 1.0 (100%) after a number of passes. Similarly, we can track the number of misclassifications per epoch, which should drop to zero as the perceptron converges. A plot of misclassification count vs. iteration would vividly show the perceptron learning (it should hit zero and stay there for a separable dataset).
* **Decision Boundary Visualization**: Since our data is 2D, we will plot the dataset points on a scatter plot (one color for each class) and overlay the learned decision boundary line. This line can be derived from the final weights $w_1, w_2, b$ as the set of points satisfying $w_1 x_1 + w_2 x_2 + b = 0$. We expect this line to neatly separate the two clusters with a clear margin. This visual confirmation is powerful evidence of success – we’ll literally see that the perceptron has “drawn” the correct line between classes.
* **Convergence Behavior**: We might also illustrate how the decision boundary moves during training. For example, we could capture snapshots of the line’s position after 1 epoch, 2 epochs, etc., showing it gradually aligning to the correct orientation. Alternatively, an animation could be insightful, but a static report might instead include a sequence of plots or a description of convergence speed (“the perceptron converged after 7 epochs”).
* **Final Weights**: We will report the final weight values and bias. This is less of a “visualization” and more of a sanity check / interpretability metric. For instance, if the perceptron finds $w_1 \approx 2.0, w_2 \approx 2.0, b \approx -1.0$, we know the boundary is roughly $2x_1 + 2x_2 = 1$, which matches our expectations for separating the clusters we made. It’s always good to verify that the learned weights make sense relative to the data distribution (and because this is a simple task, they should).
* **Perhaps Timing**: Although not usually an issue for such a simple problem, we can note how many iterations it took to converge. This can be considered a performance metric: if we use the perceptron convergence theorem as a guide, it should converge quickly. We can highlight, for example, “Perceptron converged to perfect classification in 15 iterations.”

By using these metrics and visuals, we’ll confirm that the perceptron succeeds in a scenario that plays to its strengths. The clear decision boundary on the scatter plot, coupled with perfect accuracy, will effectively demonstrate the perceptron’s capability to “learn by itself” for linearly separable patterns. This success case not only verifies our implementation, but also recreates, in miniature, Rosenblatt’s original perceptron triumph – learning to distinguish two groups by finding a linear separator.

#### 2.3. Proposed "Failure Case" Experiment

Next, to expose the perceptron’s fundamental limitation, we will test it on the classic **XOR problem**. The XOR problem is perhaps the most famous example of a task that a single-layer perceptron cannot learn. The dataset for XOR is simple and small, yet unsolvable by a linear classifier:

* Inputs are two bits $(x_1, x_2)$.
* Output should be $1$ if *exactly one* of $x_1, x_2$ is 1 (i.e., inputs are different), and $0$ if the inputs are the same.

In terms of the four possible input pairs:

* (0, 0) → 0
* (0, 1) → 1
* (1, 0) → 1
* (1, 1) → 0

Plotting these points in a 2D plane: (0,0) and (1,1) belong to class 0, while (0,1) and (1,0) belong to class 1. If you visualize them, they form the corners of a square – class 0 at the lower-left and upper-right, class 1 at the other two corners. There is **no single straight line** that can separate the orange points from the blue points in this configuration. Minsky and Papert famously proved that no perceptron can represent this function, and indeed, that result triggered much of the perceptron backlash. Thus, XOR is an ideal failure-case test: if our perceptron struggles (or outright fails) here, it will highlight *why* more advanced models are needed.

**Why XOR poses a challenge**: XOR is the prototype of a **non-linearly separable dataset**. Intuitively, the class 1 points are “in between” the class 0 points. Any attempt to draw a single line to split 1s and 0s will inevitably misclassify at least one point. In fact, the best a perceptron can do is either separate (0,0) as one class and the rest as the other (which wouldn’t match XOR), or try some line that gets three of the four points right at most. We expect that **no matter how we train the perceptron, it cannot reach 100% accuracy on XOR**. Instead, it will oscillate or settle on a line that gives, say, 75% accuracy at best (and it will never correctly classify that remaining quarter of cases). This inability is not due to a bad training procedure but due to the fundamental representational limit of a single linear boundary.

**Expected outcome**: When we run the perceptron training on XOR data, a few things are likely:

* The perceptron will **not converge** in the strict sense. Because the data is not separable, the weight updates will keep toggling the decision boundary. One epoch might make it classify (0,1) correctly but then (1,0) becomes wrong; the next epoch fixes (1,0) but breaks (0,1) again. It might enter a loop or continue to wander the weight space without settling. We will probably enforce a maximum number of epochs (to prevent infinite looping) and observe what happens.
* After training for a long time or hitting a stop condition, the perceptron’s accuracy will be well below 100%. In fact, since XOR has equal symmetry, the best it can do is 75% (it can get three out of four points right, but not the fourth). We might see the perceptron classify both (0,1) and (1,0) as 1 (that’s good) but then it might also incorrectly classify either (0,0) or (1,1) as 1 as well to keep those 1s correct – thus one of the 0 targets ends up wrong. Or vice versa.
* The error rate per epoch will not reach zero. We expect it to bounce around. Perhaps in some epochs it makes one mistake, next epoch it makes a different mistake, and so on, never eliminating all errors simultaneously.

**Diagnostics and visualizations**: To analyze this failure, we will use:

* **Plot of the Data and Any Decision Boundary**: We will again plot the four XOR points in the plane, color-coded by class. We can then try to plot the perceptron’s decision boundary line after training (or even during training). We’ll likely see a line that maybe separates one of the class 0 points but not the other. For example, it might pass between (0,0) and (0,1), correctly separating those, but then it can’t also separate (1,0) and (1,1) correctly. We might even plot multiple lines (the best the perceptron tries) to illustrate that no single line can do the job. This visualization will make it obvious that the classes are arranged in an “XOR” pattern – the positive points are diagonally placed – which is a textbook scenario of non-separability.
* **Training Trajectory**: We will monitor the perceptron’s weight updates over epochs. Perhaps we can plot how $w_1, w_2, b$ change as training proceeds. We might observe a cycle. For instance, maybe the perceptron oscillates between two sets of weights, neither of which solves the problem but each fixes the error of the other. If a cycle is detected, that’s a clear indicator of non-convergence. We could present those weight cycles as evidence.
* **Accuracy/Misclassification Plot**: Plotting the number of misclassified points each epoch will likely show a non-zero oscillating pattern. For example, it might alternate between 1 misclassification and 2 misclassifications back to 1, etc., but never drop to 0. This graph, compared to the one from the success case (which dropped to 0 and stayed there), starkly demonstrates the perceptron’s inability to find a stable solution for XOR.
* **Logical Evaluation**: Since XOR has only 4 points, we can explicitly show the perceptron’s output for each of the 4 combinations at the end of training. For instance, we might end with a perceptron that says “1 for inputs where $x_1 + x_2 > 0.5$” (just as an example). We can tabulate: for (0,0) it gives 0 (correct), (0,1) gives 1 (correct), (1,0) gives 1 (correct), (1,1) gives 1 (incorrect!). Such a table or logic check confirms the nature of the mistake. We expect one of those four will always be wrong.
* **Geometry of Failure**: To further diagnose, we might highlight how the positive points (0,1) and (1,0) lie on opposite sides of any given line through (0,0) and (1,1). A small diagram might be used to argue that any linear separator must leave one of the XOR positives with the negatives. This isn’t necessary for the experiment report, but it helps tie the empirical observation to the theory.

By examining these metrics, we’ll not only catch the perceptron failing, but we’ll see **why** it fails. The key insight is that the perceptron’s linear boundary is insufficient for XOR’s structure. This experiment will likely reproduce the historic finding of Minsky and Papert in our own simple test: no matter how we tweak the perceptron, XOR remains unsolvable for it.

One more twist: we might attempt to trick the perceptron by giving it a lot of epochs or different initial weights, just to be thorough. But the outcome should be the same. We could show, for completeness, that even if we start with different random weights, the perceptron always ends up stuck with a non-zero error. This reinforces that the failure is due to a fundamental data geometry issue, not a training hiccup.

#### 2.4. The Transition Narrative

The weakness exposed in the failure case is *exactly* the problem that the **ADELINE** was designed to solve. It addresses this by introducing a different learning approach – specifically, ADALINE (Adaptive Linear Neuron) uses a linear activation (and the **delta rule** based on continuous error) so that the neuron’s weights can adjust even for non-linearly separable cases, converging to the best possible linear fit. In essence, where the perceptron would simply fail to converge on XOR-like problems, ADELINE was intended to handle such scenarios by learning from the *magnitude* of errors (not just binary outcomes), paving the way for networks that can eventually combine multiple neurons to tackle XOR and beyond. The limitations of the perceptron’s step-function learning rule directly motivate ADELINE’s innovations – it continues the quest by taking the next step towards neurons that can learn **deeper patterns** through more refined training techniques.
